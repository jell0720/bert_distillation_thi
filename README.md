# BERT è’¸é¤¾ç¤ºç¯„å°ˆæ¡ˆ

## å°ˆæ¡ˆç°¡ä»‹

æœ¬å°ˆæ¡ˆç¤ºç¯„å¦‚ä½•ä½¿ç”¨ **bert-large-uncased** æ¨¡å‹ï¼Œåœ¨ **SST-2** (Stanford Sentiment Treebank) è³‡æ–™é›†ä¸Šé€²è¡Œ **fine-tune**ï¼Œä¸¦é€éçŸ¥è­˜è’¸é¤¾æŠ€è¡“è¨“ç·´ **bert-base-uncased** å­¸ç”Ÿæ¨¡å‹ï¼Œé”åˆ°æ›´è¼•é‡åŒ–çš„æ‡‰ç”¨ã€‚

### ä¸»è¦ç‰¹é»

- **çŸ¥è­˜è’¸é¤¾**ï¼šåˆ©ç”¨å¤§æ¨¡å‹ï¼ˆæ•™å¸«ï¼‰è¨“ç·´è¼ƒå°çš„æ¨¡å‹ï¼ˆå­¸ç”Ÿï¼‰ã€‚
- **æ•ˆèƒ½å„ªåŒ–**ï¼šæ¸›å°‘è¨ˆç®—è³‡æºéœ€æ±‚ï¼Œé©åˆå¯¦éš›éƒ¨ç½²ã€‚
- **ç°¡å–®æ˜“ç”¨**ï¼šé€é Python è…³æœ¬å³å¯å¿«é€ŸåŸ·è¡Œå®Œæ•´æµç¨‹ã€‚

---

## å°ˆæ¡ˆçµæ§‹

```
ğŸ“‚ bert-distillation
â”œâ”€â”€ distilled-bert.py        # æ¨¡å‹è’¸é¤¾ç¨‹å¼
â”œâ”€â”€ trainer_teacher.py       # æ•™å¸«æ¨¡å‹è¨“ç·´ç¨‹å¼
â”œâ”€â”€ pyproject.toml           # ä¾è³´ç®¡ç†æª”æ¡ˆ
â”œâ”€â”€ requirements.txt         # ä¾è³´å®‰è£æª”æ¡ˆï¼ˆé¸æ“‡æ€§ï¼‰
â”œâ”€â”€ LICENSE                  # æˆæ¬Šæ¢æ¬¾
â”œâ”€â”€ README.md                # æœ¬èªªæ˜æ–‡ä»¶
â””â”€â”€ data/                    # è¨“ç·´èˆ‡æ¸¬è©¦è³‡æ–™é›†ï¼ˆè«‹æ‰‹å‹•ä¸‹è¼‰ï¼‰
```

---

## ç’°å¢ƒéœ€æ±‚

- Python 3.7 ä»¥ä¸Š
- `torch`, `transformers`, `datasets`, `accelerate`
- **å»ºè­°ä½¿ç”¨ Poetry ä¾†ç®¡ç†å¥—ä»¶ä¾è³´**

å®‰è£ Poetryï¼š

```bash
pip install poetry
```

å®‰è£å°ˆæ¡ˆä¾è³´ï¼š

```bash
poetry install
```

æˆ–è€…ä½¿ç”¨ pipï¼š

```bash
pip install -r requirements.txt
```

---

## è¨“ç·´æµç¨‹

### 1. è¤‡è£½å°ˆæ¡ˆ

```bash
git clone http://gitlab.thi.com.tw/jell/bert_distillation.git
cd bert-distillation
```

### 2. æ•™å¸«æ¨¡å‹è¨“ç·´

åŸ·è¡ŒæŒ‡ä»¤å¦‚ä¸‹ï¼š

```bash
python trainer_teacher.py --data_path ./data/sst2 --output_dir ./models/teacher
```

### 3. å­¸ç”Ÿæ¨¡å‹è’¸é¤¾

åŸ·è¡Œä»¥ä¸‹æŒ‡ä»¤ï¼š

```bash
python distilled-bert.py --teacher_model ./models/teacher --output_dir ./models/student
```

---

## è’¸é¤¾æ¼”ç®—æ³•è©³ç´°èªªæ˜

### 1. **è»Ÿæ¨™ç±¤ (Soft Label) èˆ‡æº«åº¦ (Temperature)**

- å¾æ•™å¸«æ¨¡å‹ (bert-large-uncased) è¼¸å‡º logitsï¼Œç¶“ç”±ã€Œæº«åº¦åƒæ•¸ã€$T$ é€²è¡Œç¸®æ”¾ï¼Œè¨ˆç®—å‡ºè»Ÿæ¨™ç±¤ã€‚
- å…¬å¼ï¼š
  $$
  p_{teacher}(y \mid x) = \mathrm{softmax}\left(\frac{z_{teacher}}{T}\right)
  $$
  å…¶ä¸­ $z_{teacher}$ ç‚ºæ•™å¸«æ¨¡å‹ logitsã€‚
- ç•¶ $T>1$ï¼Œåˆ†å¸ƒæ›´å¹³æ»‘ï¼Œå­¸ç”Ÿæ¨¡å‹å¯å­¸ç¿’æ›´ç´°å¾®çš„è³‡è¨Šã€‚

### 2. **KL Divergence æå¤±**

- å­¸ç”Ÿæ¨¡å‹ (bert-base-uncased) ç”¢ç”Ÿ logitsï¼ŒåŒæ¨£ä½¿ç”¨æº«åº¦ $T$ ç”¢ç”Ÿè»Ÿæ¨™ç±¤ã€‚
- èˆ‡æ•™å¸«çš„è»Ÿæ¨™ç±¤é€é KL æ•£åº¦ (Kullback-Leibler Divergence) é€²è¡Œå°é½Šã€‚
- ç›®æ¨™ç‚ºæœ€å°åŒ–ï¼š
  $$
  L_{KL} = \sum_y p_{teacher}(y \mid x) \log \frac{p_{teacher}(y \mid x)}{p_{student}(y \mid x)}
  $$

### 3. **ç¡¬æ¨™ç±¤ (Hard Label) äº¤å‰ç†µæå¤±**

- å­¸ç”Ÿæ¨¡å‹åŒæ™‚å­¸ç¿’åŸå§‹è³‡æ–™çš„çœŸå¯¦æ¨™ç±¤ (0/1)ã€‚
- æå¤±å‡½æ•¸çµåˆè»Ÿæ¨™ç±¤å’Œç¡¬æ¨™ç±¤ï¼š
  $$
  L_{total} = \alpha \cdot L_{KL} + (1 - \alpha) \cdot L_{CE}
  $$
  å…¶ä¸­ $L_{CE}$ æ˜¯äº¤å‰ç†µæå¤±ã€‚

---

## è©•ä¼°èˆ‡æ‡‰ç”¨

åŸ·è¡Œæ¨¡å‹è©•ä¼°ï¼š
```bash
python evaluate.py --model ./models/student --data_path ./data/sst2/test
```

---

## å¸¸è¦‹å•é¡Œèˆ‡è§£æ±ºæ–¹æ¡ˆ

### 1. è³‡æ–™é›†ä¸‹è¼‰

```python
from datasets import load_dataset
dataset = load_dataset("stanfordnlp/sst2")
dataset.save_to_disk("./data/sst2")
```

### 2. æ¨¡å‹ä¸‹è¼‰å¤±æ•—

```bash
huggingface-cli download bert-large-uncased -d ./models/teacher
```

---

## æˆæ¬Šæ¢æ¬¾

æœ¬å°ˆæ¡ˆæ¡ç”¨ **MIT License**ï¼Œè©³ç´°å…§å®¹è«‹åƒé–± [LICENSE](./LICENSE)ã€‚

---

## è¯çµ¡æ–¹å¼

å¦‚æœ‰ä»»ä½•å•é¡Œï¼Œè«‹è¯çµ¡ [jell@thi.com.tw](mailto:jell@thi.com.tw)ã€‚

